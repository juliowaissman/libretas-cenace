{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "monetary-office",
   "metadata": {},
   "source": [
    "<center><H1>Modelo neuronal denso para la predicción de la demanda de energía eléctrica</H1><center>\n",
    "\n",
    "<center><img src=\"https://www.gstatic.com/devrel-devsite/prod/ve2848ad92313fddfcd40baeb58a2f663fe2fd55c371a714a6bb3e329e2b15223/tensorflow/images/lockup.svg\"  height=\"80px\" style=\"padding-bottom:5px;\"  /></center>\n",
    "\n",
    "<center><H2>Julio Waissman Vilanova</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-monaco",
   "metadata": {},
   "source": [
    "<table align=\"center\">\n",
    "      <td align=\"center\"><a target=\"_blank\" href=\"https://www.unison.mx\">\n",
    "            <img src=\"https://www.unison.mx/wp-content/themes/awaken/images/logo.png\"  height=\"70px\" style=\"padding-bottom:5px;\"  /></a></td>  \n",
    "      <td align=\"center\"><a target=\"_blank\" href=\"https://www.gob.mx/cenace\">\n",
    "            <img src=\"https://universidad.cenace.gob.mx/pluginfile.php/244/block_html/content/CENACE-logo-completo.png\" width=\"300\" style=\"padding-bottom:5px;\" /></a></td>\n",
    "      <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/juliowaissman/rn-cenace/blob/main/RedDensa_datos_GRNO.ipynb\">\n",
    "            <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Ejecuta en Google Colab</a></td>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-spectacular",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (15,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-newark",
   "metadata": {},
   "source": [
    "## 1. Introducción\n",
    "\n",
    "Vamos ahora a ver como preparar los datos para poderlos usar con una red densa. Los métodos que vamos a utilizar son aplicables tambien para generar series de tiempo de entrenamiento para redes recurrentes y para una combinación de CNN con LSTM.\n",
    "\n",
    "En esta libreta, al ser tipo taller, vamos a tener pocos comentarios, pero los vamos a ir completando poco a poco\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-celtic",
   "metadata": {},
   "source": [
    "## 2. Generando datos de aprendizaje\n",
    "\n",
    "Vamos aprobar algunas funciones de Keras para poder preprocesar series de tiempo, para tener una idea clara, nos vamos ainventar una serie de tiempo muy fácil de visualizar y ver como funcionan las herramientas.\n",
    "\n",
    "Así que vamos a hacer una serie de tiempo de una sola variable (pirata, realizada solo con la secuencia de números desde 0 hasta 10 mil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-mexican",
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_pirata = np.arange(10_000, dtype=np.float32)\n",
    "\n",
    "serie_pirata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-treat",
   "metadata": {},
   "source": [
    "Y ahora usaremos [`timeseries_dataset_from_array`](https://keras.io/api/preprocessing/timeseries/) para generar un conjunto de datos de aprendizaje de una sola serie (i.e. la demanda de energía)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genera_serie(serie, horizonte):\n",
    "    \"\"\"Genera una dataset para entrenar una red neuronal de una serie de tiempo\"\"\"\n",
    "    \n",
    "    input_data = serie[:-horizonte]\n",
    "    targets = serie[horizonte:]\n",
    "\n",
    "    ## Esta es la función para generar series\n",
    "    ## Vamos a probar direrentes parámetros para entender bien\n",
    "    dataset = keras.preprocessing.timeseries_dataset_from_array(\n",
    "        input_data, targets, \n",
    "        sequence_length=horizonte, \n",
    "        shuffle=False,\n",
    "        sampling_rate=1,\n",
    "        sequence_stride=1,\n",
    "        batch_size=10\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "\n",
    "dataset_pirata = genera_serie(serie_pirata, 10)\n",
    "\n",
    "for i, batch in enumerate(dataset_pirata):\n",
    "    x, y = batch\n",
    "    print(f\"x es del tipo {type(x)}\")\n",
    "    print(f\"y es del tipo {type(y)}\")\n",
    "    print(f\"Minibarch {i+1}\")\n",
    "    print(f\"x = \\n{x}\")\n",
    "    print(f\"y = {y}\")\n",
    "    if i > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-robin",
   "metadata": {},
   "source": [
    "¿Interesante no? Podemos generar un conjunto para aprender stableciendo cuantos datos anteriores vamos a usar para entrenamiento. Y estos datos ya vienen en forma de un [Dataset](https://www.tensorflow.org/guide/data) que puede ser utilizado por Tensorflow para el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-manchester",
   "metadata": {},
   "source": [
    "## 3. Cargando los datos y apartando la serie de tiempo\n",
    "\n",
    "Vamos entonces a usar los datos que nos proporcionó Jesús sobre la demanda de energñia en la Gerencia Regional Noroeste, y vamos a aprender sobre una serie de tiempo, a ver que pasa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/juliowaissman/curso-ml-cenace/raw/main/datos/Dataset_GCRNO_05052021.xlsx\"\n",
    "\n",
    "df = pd.read_excel(url, sheet_name='Datos')\n",
    "\n",
    "df_horario = df.melt(\n",
    "    id_vars= ['FECHA'],\n",
    "    value_vars= [f'DEM_GCRNO_H{i}' for i in range(24)],\n",
    "    var_name=\"Hora\",\n",
    "    value_name=\"Demanda\"\n",
    ").replace(\n",
    "    {f'DEM_GCRNO_H{i}': i for i in range(24)}\n",
    ")\n",
    "\n",
    "df_horario.index = df_horario.FECHA + pd.to_timedelta(df_horario.Hora, unit='h')\n",
    "df_horario.sort_index(inplace=True)\n",
    "df_horario.drop(columns=['FECHA', 'Hora'], inplace=True)\n",
    "df_horario = df_horario.asfreq('H', method='pad')\n",
    "\n",
    "fig = px.line(df_horario, x=df_horario.index, y=\"Demanda\", title='Demanda de energía GRNO')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_horario['DeseasonW'] = df_horario.Demanda.diff(7*24)\n",
    "fig = px.line(df_horario, x=df_horario.index, y=\"DeseasonW\", title='Incremento diario de la demanda de energía GRNO')\n",
    "fig.show()\n",
    "\n",
    "df_horario['DeseasonD'] = df_horario.Demanda.diff(24)\n",
    "fig = px.line(df_horario, x=df_horario.index, y=\"DeseasonD\", title='incremento semanal-diario del Demanda de energía GRNO')\n",
    "fig.show()\n",
    "\n",
    "df_horario['Deseason'] = df_horario.Demanda.diff()\n",
    "fig = px.line(df_horario, x=df_horario.index, y=\"Deseason\", title='incremento semanal-diario del Demanda de energía GRNO')\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-auditor",
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_train = df_horario.Demanda[df_horario.index.year < 2021].to_numpy()\n",
    "serie_test = df_horario.Demanda[df_horario.index.year == 2021].to_numpy()\n",
    "\n",
    "horizonte = 24*7 + 12 #(una semana de pasado)\n",
    "dataset_train = genera_serie(serie_train, horizonte)\n",
    "dataset_test = genera_serie(serie_test, horizonte)\n",
    "\n",
    "print(f\"Shape de serie_train = {serie_train.shape}\")\n",
    "print(f\"Shape de serie_test = {serie_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-tumor",
   "metadata": {},
   "source": [
    "## 4. Haciendo y entrenando un modelo\n",
    "\n",
    "Vamos a hacer un modelo rápido y furioso, a ver si nos sale algo bueno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo_sin_compil(nombre=\"gallina_pinta\"):\n",
    "    modelo = keras.models.Sequential(name=nombre)\n",
    "\n",
    "    #TODO: ajusta un modelo\n",
    "    modelo.add(layers.Dense(256, activation=\"relu\", input_shape=(horizonte,), name=\"capa_1\"))\n",
    "    modelo.add(layers.Dense(256, activation=\"relu\", name=\"capa_2\"))\n",
    "    modelo.add(layers.Dense(256, activation=\"relu\", name=\"capa_3\"))\n",
    "    modelo.add(layers.Dense(1, activation=\"linear\", name=\"capa_salida\"))\n",
    "    return modelo\n",
    "\n",
    "def modelo_compilado():\n",
    "    model = modelo_sin_compil()\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.MeanAbsoluteError(),\n",
    "        metrics=[\n",
    "            keras.metrics.MeanAbsolutePercentageError()\n",
    "        ],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "modelo1 = modelo_compilado()\n",
    "modelo1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-springer",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "print(f\"Entrenamiento del modelo en {num_epochs} epochs\")\n",
    "\n",
    "history = modelo1.fit(\n",
    "    dataset_train,\n",
    "    epochs=num_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = modelo1.evaluate(dataset_test)\n",
    "\n",
    "print(\"\\n\\nMAE en test, MAPE en test:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-outdoors",
   "metadata": {},
   "source": [
    "## 5. Probando que tan bien funciona\n",
    "\n",
    "Por supuesto que la evaluación es solo para ver si lo que aprendió lo puede usar con los datos de test, pero la prueba está en estimar las 36 horas, y quedarse con las 24. \n",
    "\n",
    "Vamos a hacer una función que nos permita hacer este tipo de predicciones y ver que tal nos funciona el modelo ya en la realidad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_horario.Demanda[df_horario.index.year == 2021]\n",
    "\n",
    "y_real = serie_test[horizonte + 12:]\n",
    "y_est_l = []\n",
    "\n",
    "for ini in range(0, serie_test.shape[0] - horizonte - 12, 24):\n",
    "    x = serie_test[ini:ini+horizonte]\n",
    "    for inc in range(36):\n",
    "        y = float(modelo1.predict(x.reshape(1, -1)))\n",
    "        x = np.append(x[1:], y)\n",
    "        if inc >= 12:\n",
    "            y_est_l.append(y)\n",
    "\n",
    "y_est = np.array(y_est_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estimacion = pd.DataFrame({\n",
    "    \"Fecha\": df_test.index[horizonte + 12:],\n",
    "    \"Real\": y_real,\n",
    "    \"Estimado\": y_est\n",
    "})\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df_estimacion.Fecha, y=df_estimacion.Estimado, name=\"Estimada\"))\n",
    "fig.add_trace(go.Scatter(x=df_estimacion.Fecha, y=df_estimacion.Real, name=\"Real\"))\n",
    "fig.update_layout(title=\"Estimación de la demanda\")\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-correlation",
   "metadata": {},
   "source": [
    "No está nada optimizado el código de reconocimiento, pero es más o menos funcional. Con lo que podemos probar diferentes modelos neuronales."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
