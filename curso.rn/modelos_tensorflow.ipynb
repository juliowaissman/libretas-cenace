{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "informational-wiring",
   "metadata": {},
   "source": [
    "<center><H1>Creación de modelos neuronales en</H1><center>\n",
    "\n",
    "<center><img src=\"https://www.gstatic.com/devrel-devsite/prod/ve2848ad92313fddfcd40baeb58a2f663fe2fd55c371a714a6bb3e329e2b15223/tensorflow/images/lockup.svg\"  height=\"80px\" style=\"padding-bottom:5px;\"  /></center>\n",
    "\n",
    "<center><H2>Julio Waissman Vilanova</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-profile",
   "metadata": {},
   "source": [
    "<table align=\"center\">\n",
    "      <td align=\"center\"><a target=\"_blank\" href=\"https://www.unison.mx\">\n",
    "            <img src=\"https://www.unison.mx/wp-content/themes/awaken/images/logo.png\"  height=\"70px\" style=\"padding-bottom:5px;\"  /></a></td>  \n",
    "      <td align=\"center\"><a target=\"_blank\" href=\"https://www.gob.mx/cenace\">\n",
    "            <img src=\"https://universidad.cenace.gob.mx/pluginfile.php/244/block_html/content/CENACE-logo-completo.png\" width=\"300\" style=\"padding-bottom:5px;\" /></a></td>\n",
    "      <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/juliowaissman/rn-cenace/blob/main/modelos_tensorflow.ipynb\">\n",
    "            <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Ejecuta en Google Colab</a></td>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-frame",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-spank",
   "metadata": {},
   "source": [
    "# 1 Definicion de redes simples con `Sequential`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-paradise",
   "metadata": {},
   "source": [
    "## 1.1 ¿Cuando usar un modelo tipo `Sequential`?\n",
    "\n",
    "\n",
    "Un modelo basado en `Sequential` es apropiado cuando:\n",
    "\n",
    "- Se tiene un modelo de capas en forma de una pila sencilla\n",
    "- Cada capa tiene exactamente un tensor de entrada y un tensor de salida\n",
    "\n",
    "Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-parking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo con 3 capas\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(2, activation=\"relu\", name=\"capa1\"),\n",
    "        layers.Dense(3, activation=\"relu\", name=\"capa2\"),\n",
    "        layers.Dense(4, name=\"capa3\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Prueba el modelo\n",
    "x = tf.ones((3, 3))\n",
    "y = model(x)\n",
    "print(f\"La salida es:\\n {y.numpy()}\")\n",
    "print(\"\\nY el modelo es el siguiente:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-blackberry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra forma de usar Sequential\n",
    "layer1 = layers.Dense(2, activation=\"relu\", name=\"capa1\")\n",
    "layer2 = layers.Dense(3, activation=\"relu\", name=\"capa2\")\n",
    "layer3 = layers.Dense(4, name=\"capa3\")\n",
    "\n",
    "model = keras.Sequential(name=\"Mi Modelo\")\n",
    "model.add(layer1)\n",
    "model.add(layer2)\n",
    "model.add(layer3)\n",
    "\n",
    "\n",
    "# Prueba el modelo\n",
    "x = tf.ones((3, 3))\n",
    "y = model(x)\n",
    "print(f\"La salida es:\\n {y.numpy()}\")\n",
    "print(\"\\nY el modelo es el siguiente:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-cable",
   "metadata": {},
   "source": [
    "Se pueden ir sacando capas de la pila utilizando el método `pop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-prayer",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pop()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-revolution",
   "metadata": {},
   "source": [
    "`Sequential` es la forma más sencilla de definir un modelo neuronal, por lo que no es apropiado para modelos que:\n",
    "\n",
    "- Tienen multiples entradas y salidas\n",
    "- Alguna capa tiene multiples entradas o multiples salidas\n",
    "- Se necesita compartir alguna capa\n",
    "- Una topología no lineal (i.e. resnet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-container",
   "metadata": {},
   "source": [
    "## 1.2 Especificar el `shape` de la entrada al principio\n",
    "\n",
    "Casi todos los modelos de capas y modelos desarrollados en keras se inicializan hasta que conocen su entrada (o la dimensión de esta). Por ejemplo, la siguiente capa tiene su vector de pesos vacío hasta que no se usa por primera vez:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = layers.Dense(3)\n",
    "layer.weights  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-david",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call layer on a test input\n",
    "x = tf.ones((1, 4))\n",
    "y = layer(x)\n",
    "layer.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-vacation",
   "metadata": {},
   "source": [
    "Esto pasa típicamente con los modelos basados en `Sequential`donde, mientrs no se defina la entrada, no se inicializan los pesos, y varias de las funciones no pueden usarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(2, activation=\"relu\"),\n",
    "        layers.Dense(3, activation=\"relu\"),\n",
    "        layers.Dense(4),\n",
    "    ]\n",
    ") \n",
    "\n",
    "# En este punto, no hay pesos\n",
    "#print(f\"Los pesos existentes son: {model.weights}\") \n",
    "\n",
    "# Tampoco puedes hacer este\n",
    "#display(model.summary())\n",
    "\n",
    "# Pero si se inicializa la coosa cambia\n",
    "x = tf.ones((1, 4))\n",
    "y = model(x)\n",
    "print(model.weights) \n",
    "display(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-tuner",
   "metadata": {},
   "source": [
    "Con el fin que el modelo se encuentre bien definido desde el principio, así como la asignación inicial de pesos y sesgos, se recomienda inicializar los modelos con el tamaño de la entrada. Esto se puede hacer de dos formas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-triumph",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(4,)))\n",
    "model.add(layers.Dense(2, activation=\"relu\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(2, activation=\"relu\", input_shape=(4,)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-arizona",
   "metadata": {},
   "source": [
    "# 2 Entrenamiento y evaluación básicos de redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-multiple",
   "metadata": {},
   "source": [
    "# 2.1 Introducción\n",
    "\n",
    "Aqui vamos a ver como utilizar las herramientas de entrenamiento, evaluación\n",
    "y predicción que vienen incluidas en las APIs de las formas de desarrollar modelo\n",
    "vistas en la libreta anterior y que pueden ser llamadas como `Model.fit()`,\n",
    "`Model.evaluate()` and `Model.predict()`. \n",
    "\n",
    "Si buscamos modificar el proceso de entrenamiento y evaluación a la medida, \n",
    "se pueden consultar las siguientes guías:\n",
    "\n",
    "1. Para desarrollar un paso de aprendizaje a la medida, se puede consultar la guía\n",
    "de Tensorflow 2.x [Customizing what happens in `fit()` guide](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit/).\n",
    "\n",
    "2. Para desarrollar un ciclo de entrenamiento y evaluación diferente, consultar la guía\n",
    "[\"writing a training loop from scratch\"](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch/).\n",
    "\n",
    "3. Para entrenamiento distribuido, ver la guía [guide to multi-GPU & distributed training](https://keras.io/guides/distributed_training/).\n",
    "\n",
    "Las guías en español parecen traducidas directamente con el google translate, \n",
    "por lo que recomiendo leerlas en su versión en inglés. \n",
    "\n",
    "Para ilustar el uso del aprendizaje y validación, vamos a utilizar el conjunto de datos \n",
    "más visto en el mundo del aprendizaje profundo: la base de datos de [MNIST](http://yann.lecun.com/exdb/mnist/). Afortunadamente es tan común que ya viene por default en Tensorflow y es fácil de obtener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_original, y_train), (x_test_original, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocesamiento (aplanado de los datos) \n",
    "x_train = x_train_original.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test = x_test_original.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "# Las salidas como flotantes para ser usadas por Tensorflow\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "\n",
    "# Reserva 10,000 muestras para validación\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-disabled",
   "metadata": {},
   "source": [
    "Vamos a ver algunos de los datos de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.randint(0, 50000, size=16)\n",
    "\n",
    "pl.figure(figsize=(12,12))\n",
    "for i in range(16):\n",
    "    pl.subplot(4, 4, i+1)\n",
    "    pl.imshow(x_train_original[indices[i],:,:])\n",
    "    pl.axis('off')\n",
    "    pl.title(f\"Salida = {int(y_train[indices[i]])}\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-extra",
   "metadata": {},
   "source": [
    "Y ahora, pues vamos a definir un modelo neuronal sencillo para practicar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(name=\"MiModeloMNIST\")\n",
    "model.add(keras.Input(shape=(784,), name=\"digitos\"))\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"capa_oculta_1\"))\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"capa_oculta_2\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"prediccion\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-digest",
   "metadata": {},
   "source": [
    "## 2.2 El método `compile` \n",
    "\n",
    "El método `compile`se utiliza para especificar pérdida, métrica y método de optimización\n",
    "\n",
    "Vamos a aplicarlo primero y lo vamos desglosando paso a paso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-honduras",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    # Método de optimización a utilizar\n",
    "    optimizer=keras.optimizers.RMSprop(),  \n",
    "    # Funcion de pérdida a minimizar\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # Lista con métricas para monitorear\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-equity",
   "metadata": {},
   "source": [
    "Si queremos utilizar diferentes métodos es mejor separar el modelo no compilado del modelo compilado usando funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-editing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo_no_compilado():\n",
    "    model = keras.Sequential(name=\"MiModeloMNIST\")\n",
    "    model.add(keras.Input(shape=(784,), name=\"digitos\"))\n",
    "    model.add(layers.Dense(64, activation=\"relu\", name=\"capa_oculta_1\"))\n",
    "    model.add(layers.Dense(64, activation=\"relu\", name=\"capa_oculta_2\"))\n",
    "    model.add(layers.Dense(10, activation=\"softmax\", name=\"prediccion\"))\n",
    "    return model\n",
    "\n",
    "def modelo_compilado(\n",
    "                optimizador=keras.optimizers.RMSprop(), \n",
    "                perdida=keras.losses.SparseCategoricalCrossentropy(), \n",
    "                metricas=[keras.metrics.SparseCategoricalAccuracy()]):\n",
    "    model = modelo_no_compilado()\n",
    "    model.compile(\n",
    "        optimizer=optimizador,\n",
    "        loss=perdida,\n",
    "        metrics=metricas,\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = modelo_compilado()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-howard",
   "metadata": {},
   "source": [
    "Para especificar los posibles optimizadores, funciones de pérdida y métricas que vienen ya desarrolladas por *Keras* se puede consultar la [API de Keras para métodos de optimización](https://keras.io/api/optimizers/), la [API de Keras para funciones de pérdida](https://keras.io/api/losses/) y la [API de Keras para métricas](https://keras.io/api/metrics/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-clearing",
   "metadata": {},
   "source": [
    "## 2.3 Aplicando `fit`, `evaluate` y `predict`\n",
    "\n",
    "Ya con un modelo compilado podemos pasar a la fase de entrenamiento y evaluación del modelo, para lo que vamos a usar las funciones `fit`y `evaluate`. Empecemos con `fit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-admission",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 4\n",
    "print(f\"Entrenamiento del modelo en {num_epochs} epochs\")\n",
    "history = modelo.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=num_epochs,\n",
    "    # Datos de validación para medir el aprendizaje al final de cada epoch\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-cooling",
   "metadata": {},
   "source": [
    "En `history` se tiene información de la fase de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-burlington",
   "metadata": {},
   "source": [
    "Si los datos de entrenamiento se mantienen en `ndarray`de numpy (como en este caso),\n",
    "entonces es posible no necesiotar separar explicitamente los datos de entrenamiento\n",
    "y validación, si no simplemente decir en `fit` que porcentaje de los datos deben ser\n",
    "utilizados para validación y el método se encarga de dividirlos.\n",
    "\n",
    "Por ejemplo, si se quisiera utilizar el 20% de los datos para validación se podría\n",
    "utilizar el siguiente código (asumiendo que no los hubieramos separado ya los datos)\n",
    "\n",
    "```python\n",
    "modelo = modelo_compilado()\n",
    "modelo.fit(x_train, y_train, batch_size=64, validation_split=0.2, epochs=1)\n",
    "```\n",
    "\n",
    "Para evaluar el modelo, vamos a revisar las métricas establecidas pero con los datos de prueba usando `evaluate`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluando en los datos de prueba\")\n",
    "\n",
    "results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "\n",
    "print(\"\\n\\nPérdida en test, Accuracy en test:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-beatles",
   "metadata": {},
   "source": [
    "Por último, vamos a predecir los valores en los primeros 3 datos del conjunto de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-guard",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Prediciendo para 3 ejemplos\")\n",
    "predict = model.predict(x_test[:3])\n",
    "print(\"Shape de predict:\", predict.shape)\n",
    "print(\"\\nY las predicciones son:\")\n",
    "print(predict)\n",
    "print(\"\\nY si queremos las clases, pues usamos `argmax` de numpy\")\n",
    "print(predict.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-company",
   "metadata": {},
   "source": [
    "## 2.4 Guardando y cargando modelos\n",
    "\n",
    "¿Para que entrenar un modelo si no lo vamos a volver a usar? Para guardar un modelo entrenado (y volverlo a cargar) Keras ofrece una interface, en la cual se guarda en un único archivo toda la información sobre un modelo y se puede volver a cargar en forma transparente.\n",
    "\n",
    "Guardemos y carguemos de nuevo nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-living",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.save(\"modelito.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-found",
   "metadata": {},
   "outputs": [],
   "source": [
    "otro_modelo = keras.models.load_model(\"modelito.h5\")\n",
    "\n",
    "print(\"Prediciendo para los mismos 3 ejemplos\")\n",
    "predict = otro_modelo.predict(x_test[:3])\n",
    "print(\"Shape de predict:\", predict.shape)\n",
    "print(\"\\nY las predicciones son:\")\n",
    "print(predict)\n",
    "print(\"\\nY si queremos las clases, pues usamos `argmax` de numpy\")\n",
    "print(predict.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-medication",
   "metadata": {},
   "source": [
    "Cuando entrenamos con modelos muy complicados o muchos datos, es posible que algo pase y se nos pierda lel entrenamiento a la mitad, o peor aun, casi terminandolo, lo que es una desgracia. Afortunadamente en Keras es posible ir generando archivos de checkpoint como sigue:\n",
    "\n",
    "```python\n",
    "\n",
    "modelo = modelo_compilado()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"mymodel_{epoch}\",\n",
    "        save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=1,\n",
    "    )\n",
    "]\n",
    "model.fit(\n",
    "    x_train, y_train, epochs=2, batch_size=64, callbacks=callbacks, validation_split=0.2\n",
    ")\n",
    "```\n",
    "\n",
    "Intenta probarlo y revisa que resultados te da y donde se guardan los archivos de checkpoint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
