{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "forecasting_demanda_energia.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J45RcFQyv7oL"
      },
      "source": [
        "<center>\n",
        "<p><img src=\"https://www.gob.mx/cms/uploads/image/file/179499/outstanding_quienes-somos.jpg\" width=\"300\">\n",
        "</p>\n",
        "\n",
        "\n",
        "\n",
        "# Curso *Machine Learning con uso de pandas, scikit learn y libretas jupyter*\n",
        "\n",
        "# Uso de `scikit-learn` y `skforcast` para predicción del consumo de energía eléctrica. \n",
        "\n",
        "\n",
        "<p> Julio Waissman Vilanova </p>\n",
        "<p>\n",
        "<img src=\"https://identidadbuho.unison.mx/wp-content/uploads/2019/06/letragrama-cmyk-72.jpg\" width=\"80\">\n",
        "</p>\n",
        "</center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iu_tu_4pwRS-"
      },
      "source": [
        "En este documento se muestra un ejemplo de cómo utilizar métodos de *forecasting* para predecir la demanda eléctrica en Hermosillo a nivel horario. Vamos a utilizar un conjunto de datos que puso generosamente a nuestra disposición [Hector Alberto Gutierrez Ibarra](hector.gutierrez@cenace.gob.mx) de la gerencia noroeste.\n",
        "\n",
        "Para ello, se hace uso de [`skforecast`](https://github.com/JoaquinAmatRodrigo/skforecast), una librería de Python que permite adaptar cualquier regresor de `scikit-learn` a problemas de forecasting. Esta libreta retoma en gran parte el trabajo de [Joaquín Amat](https://www.cienciadedatos.net/index.html) en su muy interesante post sobre [Predicción (forecasting) de la demanda eléctrica con Python](https://www.cienciadedatos.net/documentos/py29-forecasting-demanda-energia-electrica-python.html).\n",
        "\n",
        "iniciemos instalando las bibliotecas que no vienen por *default* en Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGy9S-DpypAr"
      },
      "source": [
        "!pip install skforecast"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahJ4TgeTzBsZ"
      },
      "source": [
        "## Cargando el conjunto de datos y limpiandolo\n",
        "\n",
        "Vamos a repetir algunos pasos que ya hicimos en una libreta pasada en el procesamiento de la información. Al mismo tiempo, vamos a agregar una información nueva, la información sobre los días festivos. Tambien vamos a incluir una columna sólo con la fecha, para diferenciar de la hora.\n",
        "\n",
        "Un problema importante para poder aplicar los métodos de autoregresión que vamos a ver más adelante, es que es necesario asegurarse que los datos se encuentren separados a intervalos de tiempo regular (en nuestro caso a 1 hora).\n",
        "\n",
        "De no ser así es necesario realizar un procedimiento de imputación de datos, y asignarles, ya sea un valor numérico, ya sea marcar explicitamente como un dato perdido. Para eso vamos a usar la función `pd.asfreq` que nos asegura una serie a intervalos regulares. Siempre hay que estar muy pendientes para evitar usar datos futuros en el pasado.\n",
        "\n",
        "Vamos a los datos:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mda35Gfhv0-r"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://github.com/juliowaissman/curso-ml-cenace/raw/main/datos/caso_zc_hmo.csv.zip\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "df['Date'] = pd.to_datetime(df.Date, format=\"%d/%m/%Y %H:%M\")\n",
        "df.index = df.Date\n",
        "df = df.asfreq('H', method='pad')\n",
        "df.rename(\n",
        "    columns={\n",
        "        'Date': 'Fecha',\n",
        "        'Demand': 'Demanda',\n",
        "        'Temperature': 'Temperatura',\n",
        "        'PrecipIntensity': 'Precipitación',\n",
        "        'Humidity': 'Humedad',\n",
        "        'WinSpeed': 'VelocidadViento',\n",
        "    },\n",
        "    inplace=True\n",
        ")\n",
        "df['Dia'] = df.Fecha.dt.day_of_week\n",
        "df['Mes'] = df.Fecha.dt.month\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6r3T8WK0E26"
      },
      "source": [
        "Ahora vamos a agregar una columna con los días festivos de Mexico gracias a la biblioteca `holidays`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLZjxVEU4HNZ"
      },
      "source": [
        "!pip install holidays"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKqG-mY90FTB"
      },
      "source": [
        "import holidays\n",
        "\n",
        "festivos = list(holidays.MEX(years=[2016, 2017, 2018, 2019, 2020, 2021]).keys())\n",
        "df['Festivos'] = 1\n",
        "df.Festivos.where(df.Fecha.dt.date.isin(festivos), 0, inplace=True)\n",
        "df.Festivos.plot()\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEP9gmoD7sYY"
      },
      "source": [
        "Ahora veamos si hay diferencias en el consumo de energía entre los días festivos y los domingos y los otros días"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0CSZisC7b1w"
      },
      "source": [
        "df[['Demanda']].groupby(df.Festivos).boxplot(subplots=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jugBwPrdaFc"
      },
      "source": [
        "## Multi-Step Time Series Forecasting\n",
        "\n",
        "Cuando se trabaja con series temporales, raramente se quiere predecir solo el siguiente elemento de la serie $x_{t+1}$, sino todo un intervalo futuro o un punto alejado en el tiempo $x_{t+n}$. A cada paso de predicción se le conoce como *step*. Existen varias estrategias que permiten generar este tipo de predicciones múltiples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA9a-hpjvS9e"
      },
      "source": [
        "### Recursive multi-step forecasting \n",
        "\n",
        "Dado que, para predecir $x_{t+n}$ se necesita $x_{t+n-1}$, pero $x_{t+n-1}$ se desconoce, es necesario hacer predicciones recursivas en las que, cada nueva predicción, se basa en la predicción anterior. A este proceso se le conoce como *recursive forecasting* o *recursive multi-step forecasting*.\n",
        "\n",
        "![](https://www.cienciadedatos.net/images/forecasting_multi-step.gif)\n",
        "\n",
        "La principal adaptación que se necesita hacer para aplicar modelos de *scikit-learn* a problemas de *recursive multi-step forecasting* es transformar la serie temporal en un matriz en la que, cada valor, está asociado a la ventana temporal (lags) que le preceden. Esta estrategia de forecasting pueden generarse fácilmente con las clases `ForecasterAutoreg` y `ForecasterAutoregCustom` de la librería `skforecast`.\n",
        "\n",
        "![](https://www.cienciadedatos.net/images/transform_timeseries.gif)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaE5GkiDvaMy"
      },
      "source": [
        "### Direct multi-step forecasting \n",
        "\n",
        "El método *direct multi-step forecasting* consiste en entrenar un modelo distinto para cada *step*. Por ejemplo, si se quieren predecir los siguientes 5 valores de una serie temporal, se entrenan 5 modelos distintos, uno para cada step. Como resultado, las predicciones son independientes unas de otras.\n",
        "\n",
        "La principal complejidad de esta aproximación consiste en generar correctamente las matrices de entrenamiento para cada modelos. Todo este proceso está automatizado en la clase `ForecasterAutoregMultiOutput` de la librería `skforecast`. En el siguiente esquema se muestra el proceso para un caso en el que se dispone de la variable respuesta y dos variables exógenas.\n",
        "\n",
        "![](https://www.cienciadedatos.net/images/diagram_skforecast_multioutput.png)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLZ_IvX8vdfs"
      },
      "source": [
        "## Preparando los datos para el aprendizaje\n",
        "\n",
        "En series de tiempo, se acostumbra entrenar con la mayor parte de los datos y utilizar sólo los últimos datos para prueba. En nuestro caso vamos a ser ambiciosos/inocentes, y vamos a utilizar como datos de validación todos los datos del 2021, y todos los datos anteriores para el entrenamiento.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UztzMKMed8LU"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "\n",
        "df_train = df[df.index.year < 2021]\n",
        "df_val = df[df.index.year == 2021]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 4))\n",
        "df_train.Demanda.plot(ax=ax, label='entrenamiento', linewidth=0.5)\n",
        "df_val.Demanda.plot(ax=ax, label='validación', linewidth=0.5)\n",
        "ax.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zf5VnsUKnfKX"
      },
      "source": [
        "## Modelo pseudo autoregresivo recursivo con regresores de *scikit-learn*\n",
        "\n",
        "Vamos a iniciar el uso de `skforcaster` creando y entrenando un modelo autorregresivo recursivo (`ForecasterAutoreg`) a partir de un modelo de regresión lineal con penalización `Ridge` y una ventana temporal de 24 lags. Esto último significa que, para cada predicción, se utilizan como predictores la demanda de las 24 horas anteriores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C4nW77fvFPh"
      },
      "source": [
        "### Entrenamiento del Forecaster\n",
        "\n",
        "Vamos a ir cargando las librerías conforme las vayamos necesitando en el afan de ejemplificar mejor el uso de las herramientas. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVjH3h2MohD4"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
        "\n",
        "forecaster = ForecasterAutoreg(\n",
        "  regressor= Ridge(normalize=True),\n",
        "  lags= 24\n",
        ")\n",
        "\n",
        "forecaster.fit(y=df_train.Demanda)\n",
        "forecaster"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XQbtoY7p6vB"
      },
      "source": [
        "### Predicción (*backtest*)\n",
        "\n",
        "Para evaluar el comportamiento del modelo entrenado, vamos a evalúa el comportamiento que habría tenido el modelo si  después, a las 23:59 de cada día, se predijesen las 24 horas siguientes. Toda la serie completa (datos de entrenamiento y prueba)\n",
        "\n",
        "A este tipo de evaluación se le conoce como *backtesting*, y puede aplicarse fácilmente con la función `backtesting_forecaster()`. Esta función devuelve, además de las predicciones, una métrica de error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXm663_6pH3c"
      },
      "source": [
        "from skforecast.model_selection import backtesting_forecaster\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "\n",
        "metrica, predicciones = backtesting_forecaster(\n",
        "    forecaster= forecaster,\n",
        "    y= df.Demanda,\n",
        "    initial_train_size = len(df_train.Demanda),\n",
        "    steps= 24,\n",
        "    metric= 'mean_absolute_error',\n",
        "    verbose= True\n",
        ")\n",
        "\n",
        "# Se añade el índice temporal a las predicciones\n",
        "predicciones = pd.Series(data=predicciones, index=df_val.index)\n",
        "\n",
        "print(f\"Error MAP = {metrica}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luM1LvchsL-K"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 7))\n",
        "df_val.loc[predicciones.index, 'Demanda'].plot(ax=ax, linewidth=2, label='validación')\n",
        "predicciones.plot(ax=ax, linewidth=2, label='predicción')\n",
        "ax.set_title('Predicción vs demanda real')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbNb828nuKKF"
      },
      "source": [
        "y como es dificil ver algo, vamos haciendo un zoom por semana del año:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yUQDQOAs7zO"
      },
      "source": [
        "semana = 15\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 7))\n",
        "\n",
        "df_val.loc[\n",
        "    predicciones.index.isocalendar().week == semana, \n",
        "    'Demanda'\n",
        "].plot(ax=ax, linewidth=2, label='validación')\n",
        "\n",
        "predicciones[\n",
        "    predicciones.index.isocalendar().week == semana\n",
        "].plot(ax=ax, linewidth=2, label='predicción')\n",
        "\n",
        "ax.set_title('Predicción vs demanda real')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOaZ-VDju2BV"
      },
      "source": [
        "### Optimización de hiperparámetros (tuning)\n",
        "\n",
        "\n",
        "En el objeto ForecasterAutoreg entrenado, se han utilizado los primeros 24 lags y un modelo Ridge con los hiperparámetros por defecto. Sin embargo, no hay ninguna razón por la que estos valores sean los más adecuados.\n",
        "\n",
        "Con el objetivo de identificar la mejor combinación de lags e hiperparámetros, se recurre a un *Grid Search* con validación por *backtesting*. Este proceso consiste en entrenar un modelo con cada combinación de hiperparámetros y lags, y evaluar su capacidad predictiva mediante *backtesting*. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycMZPgeiv5-d"
      },
      "source": [
        "import numpy as np\n",
        "from skforecast.model_selection import grid_search_forecaster\n",
        "\n",
        "forecaster = ForecasterAutoreg(\n",
        "    regressor= Ridge(normalize=True),\n",
        "    lags= 24 # Este valor será remplazado en el grid search\n",
        ")\n",
        "\n",
        "# Hiperparámetros del regresor\n",
        "param_grid = {'alpha': np.logspace(-3, 3, 10)}\n",
        "\n",
        "# Lags utilizados como predictores\n",
        "lags_grid = [5, 24, [1, 2, 3, 23, 24, 25, 47, 48, 49]]\n",
        "\n",
        "resultados_grid = grid_search_forecaster(\n",
        "    forecaster= forecaster,\n",
        "    y= df_train.Demanda,\n",
        "    param_grid= param_grid,\n",
        "    lags_grid= lags_grid,\n",
        "    steps= 24,\n",
        "    metric= 'mean_absolute_error',\n",
        "    method= 'backtesting',\n",
        "    initial_train_size = len(df_train.Demanda[df_train.index.year < 2020]),\n",
        "    return_best= True,\n",
        "    verbose= False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I4JF_RcyQwT"
      },
      "source": [
        "resultados_grid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN9KF5x6x5S6"
      },
      "source": [
        "Los mejores resultados se obtienen si se utilizan los lags [1, 2, 3, 23, 24, 25, 47, 48, 49] y una $\\alpha = 0.001$ para el método de regresión `Ridge`. \n",
        "\n",
        "Al indicar `return_best = True` en la función `grid_search_forecaster()`, al final del proceso, se reentrena automáticamente el objeto forecaster con la mejor configuración encontrada y el set de datos completo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB9FP_Pix-kc"
      },
      "source": [
        "forecaster"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mxMFvO4zBGw"
      },
      "source": [
        "Revisemos si este algoritmo mejora respecto al anterior que no usamos una búsqueda ávida de los mejores parámetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H44fGXCzMrC"
      },
      "source": [
        "metrica, predicciones = backtesting_forecaster(\n",
        "    forecaster= forecaster,\n",
        "    y= df.Demanda,\n",
        "    initial_train_size = len(df_train.Demanda),\n",
        "    steps= 24,\n",
        "    metric= 'mean_absolute_error',\n",
        "    verbose= True\n",
        ")\n",
        "\n",
        "# Se añade el índice temporal a las predicciones\n",
        "predicciones = pd.Series(data=predicciones, index=df_val.index)\n",
        "\n",
        "print(f\"Error MAP = {metrica}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD11JwvzzWN7"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 7))\n",
        "df_val.loc[predicciones.index, 'Demanda'].plot(ax=ax, linewidth=2, label='validación')\n",
        "predicciones.plot(ax=ax, linewidth=2, label='predicción')\n",
        "ax.set_title('Predicción vs demanda real')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5alw9yyvzdRH"
      },
      "source": [
        "semana = 15\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 7))\n",
        "\n",
        "df_val.loc[\n",
        "    predicciones.index.isocalendar().week == semana, \n",
        "    'Demanda'\n",
        "].plot(ax=ax, linewidth=2, label='validación')\n",
        "\n",
        "predicciones[\n",
        "    predicciones.index.isocalendar().week == semana\n",
        "].plot(ax=ax, linewidth=2, label='predicción')\n",
        "\n",
        "ax.set_title('Predicción vs demanda real')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpgoLSgXzlFy"
      },
      "source": [
        "Pues al parecer el error se redujo a la mitad, auque todavía hay bastante espacio para mejorar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbrtFwByz0H-"
      },
      "source": [
        "### Intervalos de predicción\n",
        "\n",
        "\n",
        "Un intervalo de predicción define el intervalo dentro del cual es de esperar que se encuentre el verdadero valor de  𝑦\n",
        "y\n",
        " con una determinada probabilidad.\n",
        "\n",
        "Rob J Hyndman y George Athanasopoulos, listan en su libro [Forecasting: Principles and Practice](https://otexts.com/fpp2/) mútiples formas de [estimar intervalos de predicción](https://otexts.com/fpp2/prediction-intervals.html), la mayoría los cuales requieren que los resudios (errores) del modelo se distribuyan de forma normal. Cuando no se puede asumir esta propiedad, se puede recurrir a *bootstrapping*, que *solo* asume que los residuos no están correlacionados. Este es el método utilizado en la librería `skforecast` para los modelos de tipo `ForecasterAutoreg` y `ForecasterAutoregCustom`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJEU4RZK05Gj"
      },
      "source": [
        "from skforecast.model_selection import backtesting_forecaster_intervals\n",
        "\n",
        "metric, predictions = backtesting_forecaster_intervals(\n",
        "    forecaster= forecaster,\n",
        "    y= df.Demanda,\n",
        "    initial_train_size = len(df_train.Demanda),\n",
        "    steps= 24,\n",
        "    metric= 'mean_absolute_error',\n",
        "    interval= [10, 90],\n",
        "    n_boot= 500,\n",
        "    in_sample_residuals= True,\n",
        "    verbose= True\n",
        ")\n",
        "\n",
        "print('Métrica backtesting:', metric)\n",
        "\n",
        "# Se añade índice datetime\n",
        "predictions = pd.DataFrame(data=predictions, index=df_val.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-uY9DDo18Ro"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 7))\n",
        "df_val.loc[predictions.index, 'Demanda'].plot(\n",
        "    ax=ax, lw=2, label='validación' \n",
        ")\n",
        "predictions.iloc[:, 0].plot(\n",
        "    ax=ax, lw=2, label='predicción' \n",
        ")\n",
        "ax.fill_between(\n",
        "    predictions.index,\n",
        "    predictions.iloc[:, 1],\n",
        "    predictions.iloc[:, 2],\n",
        "    alpha = 0.2,\n",
        "    color = 'red',\n",
        "    label = 'Intervalo predicción' \n",
        ")\n",
        "ax.set_title('Predicción vs demanda real')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md5NdsEb21m5"
      },
      "source": [
        "Y de nuevo, mejor lo vemos por semana"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrkT--CU21MX"
      },
      "source": [
        "semana = 15\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 7))\n",
        "df_val.loc[predictions.index.isocalendar().week == semana, 'Demanda'].plot(\n",
        "    ax=ax, lw=2, label='validación' \n",
        ")\n",
        "predictions.loc[predictions.index.isocalendar().week == semana, 0].plot(\n",
        "    ax=ax, lw=2, label='predicción' \n",
        ")\n",
        "ax.fill_between(\n",
        "    predictions[predictions.index.isocalendar().week == semana].index,\n",
        "    predictions.loc[predictions.index.isocalendar().week == semana, 1],\n",
        "    predictions.loc[predictions.index.isocalendar().week == semana, 2],\n",
        "    alpha = 0.2,\n",
        "    color = 'red',\n",
        "    label = 'Intervalo predicción' \n",
        ")\n",
        "ax.set_title('Predicción vs demanda real')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPVId-jO4kY-"
      },
      "source": [
        "¿Qué porcentaje de tiempo la demanda real estuvo dentro del intervalo de confianza de la predicción? Este es un buen indicador de la bondad del modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENkYQf4Y4ykK"
      },
      "source": [
        "dentro_intervalo = np.where(\n",
        "  (df_val.Demanda >= predictions.iloc[:, 1]) & \\\n",
        "  (df_val.Demanda <= predictions.iloc[:, 2]),\n",
        "  True,\n",
        "  False\n",
        ")\n",
        "\n",
        "cobertura = dentro_intervalo.mean()\n",
        "print(f\"Cobertura del intervalo predicho: {100 * cobertura:.2f}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHJ0h_cP5e_w"
      },
      "source": [
        "El intervalo predicho tiene una cobertura inferior a la que cabría esperar (80%). Las razones se deben buscar en los días donde la predicción estuvo fuera de rango. Las razones pueden ser por ser días atípicos (domingos o festivos), o por situaciones meteorológicas entre otras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsmOUjjR5yb5"
      },
      "source": [
        "### Predicción diaria anticipada\n",
        "\n",
        "En el apartado anterior, se evaluó el modelo asumiendo que las predicciones del día siguiente se ejecutan justo al final del día anterior. En la práctica, esto no resulta muy útil ya que, para las primeras horas del día, apenas se dispone de anticipación.\n",
        "\n",
        "Supóngase ahora que, para poder tener suficiente margen de acción, a las 11:00 horas de cada día se tienen que generar las predicciones del día siguiente. Es decir, a las 11:00 del dia $D$ se tienen que predecir las horas [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23] de ese mismo día, y las horas [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23] del día $D+1$. Esto implica que se tienen que predecir un total de 36 horas a futuro.\n",
        "\n",
        "El proceso de *backtesting* adaptado a este escenario es:\n",
        "\n",
        "1. A las 11:00h del primer día del conjunto de test, se predicen las 36 siguientes horas (las 12 horas que quedan del día más las 24 horas de el día siguiente).\n",
        "\n",
        "2. Se almacenan solo las predicciones del día siguiente, es decir, de la posición 12 en adelante.\n",
        "\n",
        "3. Se añaden los datos de test hasta las 11:00 del día siguiente.\n",
        "\n",
        "4. Se repite el proceso.\n",
        "\n",
        "De esta forma, a las 11:00h de cada día, el modelo tiene acceso a los valores reales de demanda registrados hasta ese momento.\n",
        "\n",
        "Este proceso puede realizarse *fácilmente* con el método `predict()` de un objeto `ForecasterAutoreg`. Si no se le indica nada, la predicción se inicia después del último valor de entrenamiento, pero, si se le especifica el argumento `last_window`, utiliza estos valores como punto de partida.\n",
        "\n",
        "Anexamos a contunuación una función que no está dentro de ´skforcast` pero que no tardará en ser agregada a la biblioteca."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrO097py7Ps3"
      },
      "source": [
        "def backtest_predict_next_24h(\n",
        "    forecaster, y, hour_init_prediction, exog=None, verbose=False):\n",
        "    '''\n",
        "    Backtest ForecasterAutoreg object when predicting 24 hours of day D+1\n",
        "    statring at specific hour of day D.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    forecaster : ForecasterAutoreg \n",
        "        ForecasterAutoreg object already trained.\n",
        "        \n",
        "    y : pd.Series with datetime index sorted\n",
        "        Test time series values. \n",
        "        \n",
        "    exog : pd.Series or pd.Dataframe with datetime index sorted\n",
        "        Test values of exogen variable. \n",
        "    \n",
        "    hour_init_prediction: int \n",
        "        Hour of day D to start predictions of day D+1.\n",
        "\n",
        "\n",
        "    Returns \n",
        "    -------\n",
        "    predictions: pd.Series\n",
        "        Value of predictions.\n",
        "\n",
        "    '''\n",
        "    \n",
        "    y = y.sort_index()\n",
        "    if exog is not None:\n",
        "        exog = exog.sort_index()\n",
        "        \n",
        "    dummy_steps = 24 - (hour_init_prediction + 1)\n",
        "    steps = dummy_steps + 24\n",
        "    \n",
        "    # First position of `hour_init_prediction` in the series where there is enough\n",
        "    # previous window to calculate lags.\n",
        "    for datetime in y.index[y.index.hour == hour_init_prediction]:\n",
        "        if len(y[:datetime]) >= len(forecaster.last_window):\n",
        "            datetime_init_backtest = datetime\n",
        "            print(f\"Backtesting starts at day: {datetime_init_backtest}\")\n",
        "            break\n",
        "    \n",
        "    days_backtest = np.unique(y[datetime_init_backtest:].index.date)\n",
        "    days_backtest = pd.to_datetime(days_backtest)\n",
        "    days_backtest = days_backtest[1:]\n",
        "    print(f\"Days predicted in the backtesting: {days_backtest.strftime('%Y-%m-%d').values}\")\n",
        "    print('')\n",
        "    backtest_predictions = []\n",
        "    \n",
        "    for i, day in enumerate(days_backtest):        \n",
        "        # Start and end of the last window used to create the lags\n",
        "        end_window = (day - pd.Timedelta(1, unit='day')).replace(hour=hour_init_prediction)\n",
        "        start_window = end_window - pd.Timedelta(forecaster.max_lag, unit='hour')\n",
        "        last_window = y.loc[start_window:end_window]\n",
        "               \n",
        "        if exog is None:\n",
        "            if verbose:\n",
        "                print(f\"Forecasting day {day.strftime('%Y-%m-%d')}\")\n",
        "                print(f\"Using window from {start_window} to {end_window}\")\n",
        "                \n",
        "            pred = forecaster.predict(steps=steps, last_window=last_window)\n",
        "            \n",
        "        else:\n",
        "            start_exog_window = end_window + pd.Timedelta(1, unit='hour')\n",
        "            end_exog_window   = end_window + pd.Timedelta(steps, unit='hour')\n",
        "            exog_window = exog.loc[start_exog_window:end_exog_window]\n",
        "            exog_window = exog_window.to_numpy()\n",
        "            \n",
        "            if verbose:\n",
        "                print(f\"Forecasting day {day.strftime('%Y-%m-%d')}\")\n",
        "                print(f\"    Using window from {start_window} to {end_window}\")\n",
        "                print(f\"    Using exogen variable from {start_exog_window} to {end_exog_window}\")\n",
        "            \n",
        "            pred = forecaster.predict(steps=steps, last_window=last_window, exog=exog_window)\n",
        "\n",
        "        # Only store predictions of day D+1\n",
        "        pred = pred[dummy_steps:]\n",
        "        backtest_predictions.append(pred)\n",
        "    \n",
        "    backtest_predictions = np.concatenate(backtest_predictions)\n",
        "    # Add datetime index\n",
        "    backtest_predictions = pd.Series(\n",
        "                             data  = backtest_predictions,\n",
        "                             index = pd.date_range(\n",
        "                                        start = days_backtest[0],\n",
        "                                        end   = days_backtest[-1].replace(hour=23),\n",
        "                                        freq  = 'h'\n",
        "                                    )\n",
        "                           )\n",
        "    \n",
        "    return backtest_predictions"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdCOWAAI7r30"
      },
      "source": [
        "y ahora la vamos a usar (como se puede usar en otros problemas con el mismo tipo de problemas)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN2sr8Om7yMB"
      },
      "source": [
        "predicciones = backtest_predict_next_24h(\n",
        "  forecaster= forecaster,\n",
        "  y= df_val.Demanda,\n",
        "  hour_init_prediction= 11,\n",
        "  verbose= False\n",
        ")\n",
        "\n",
        "error = mean_absolute_error(\n",
        "    y_true= df_val.loc[predicciones.index, 'Demanda'],\n",
        "    y_pred= predicciones\n",
        ")\n",
        "print(f\"Error de backtest (MAP): {error}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMpYkKq48jTx"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 7))\n",
        "df_val.loc[predicciones.index, 'Demanda'].plot(ax=ax, lw=2, label='validación')\n",
        "predicciones.plot(ax=ax, lw=2, label='predicción')\n",
        "ax.set_title('Predicción vs demanda real')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Qww1fJn80lT"
      },
      "source": [
        "semana = 15\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 7))\n",
        "\n",
        "df_val.loc[ \n",
        "    df_val.index.isocalendar().week == semana, 'Demanda'\n",
        "].plot(ax=ax, linewidth=2, label='validación')\n",
        "\n",
        "predicciones[\n",
        "    predicciones.index.isocalendar().week == semana\n",
        "].plot(ax=ax, linewidth=2, label='predicción')\n",
        "\n",
        "ax.set_title('Predicción vs demanda real')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YqmkU_A-H2M"
      },
      "source": [
        "Como era de esperar, al aumentar el horizonte de predicción de 24 a 36 horas, también lo hace el error de las predicciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0WK9Zqj-JZb"
      },
      "source": [
        "### Importancia predictores\n",
        "\n",
        "Dado que el objeto `ForecasterAutoreg` utiliza modelos *scikit-learn*, una vez entrenado, se puede acceder a la importancia de los predictores. Cuando el regresor empleado es un `LinearRegression()`, `Lasso()` o `Ridge()`, la importancia queda reflejada en los coeficientes del modelo, que se obtienen con el método `get_coef()`. En regresores  `GradientBoostingRegressor()` o `RandomForestRegressor()`, la importancia de los predictores está basada en la reducción de impureza y es accesible mediante el método `get_feature_importances()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qs9v7obV-n6J"
      },
      "source": [
        "importancia = pd.DataFrame({\n",
        "    'lag': forecaster.lags, \n",
        "    'coeficiente': forecaster.get_coef()\n",
        "})\n",
        "\n",
        "importancia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYydTRc-_yQ5"
      },
      "source": [
        "## Forecasting con variables exógenas\n",
        "\n",
        "En el ejemplo anterior, se han utilizado como predictores únicamente lags de la propia variable objetivo. En ciertos escenarios, es posible disponer de información sobre otras variables, cuyo valor a futuro se conoce, y que pueden servir como predictores adicionales en el modelo. Algunos ejemplos típicos son:\n",
        "\n",
        "- Festivos (local, nacional...)\n",
        "- Mes del año\n",
        "- Día de la semana\n",
        "- Hora del día\n",
        "\n",
        "En este caso de uso, el análisis gráfico mostraba evidencias de que, los días festivos, la demanda es menor. Si un día es festivo o no, puede saberse a futuro, por lo que se puede emplear como variable exógena. Véase cómo afecta al modelo si se incluye como predictor la variable `Festivo disponible en el dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncoic2TxAJze"
      },
      "source": [
        "### Entrenamiento del Forecaster\n",
        "\n",
        "El uso de variables exógenas es directo de los mñetodos que ya hemos utilizado\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZYuicifA0SM"
      },
      "source": [
        "forecaster = ForecasterAutoreg(\n",
        "  regressor= Ridge(alpha=0.001, normalize=True),\n",
        "  lags= [1, 2, 3, 23, 24, 25, 47, 48, 49],\n",
        ")\n",
        "forecaster.fit(y=df_train.Demanda, exog=df_train.Festivos)\n",
        "forecaster"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DFmH7kfBgaH"
      },
      "source": [
        "### Predicción diaria anticipada\n",
        "\n",
        "\n",
        "Se repite de nuevo el proceso de backtesting en el que, a las 11:00 horas de cada día, se tienen que obtener las predicciones del día siguiente. Esta vez, incluyendo como predictor si el día es festivo o no."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYNrnHvhBm5x"
      },
      "source": [
        "predicciones = backtest_predict_next_24h(\n",
        "    forecaster= forecaster,\n",
        "    y= df_val.Demanda,\n",
        "    exog= df_val.Festivos,\n",
        "    hour_init_prediction= 11,\n",
        "    verbose= False\n",
        ")\n",
        "\n",
        "error = mean_absolute_error(\n",
        "    y_true= df_val.loc[predicciones.index, 'Demanda'],\n",
        "    y_pred= predicciones\n",
        ")\n",
        "print(f\"Error de backtest (MAP): {error}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrK3dLcjCneu"
      },
      "source": [
        "Los días festivos al parecer no tienen gran influencia en la demanda de energía, al menos en el 2021.\n",
        "\n",
        "Veamos que pasa si agregamos como variables exógenas el día de la semana, el mes del año y la hora del día."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYQ4xOd8DSxw"
      },
      "source": [
        "# Agregamos hora que no lo habíamos hecho antes\n",
        "df['Hora'] = df.Fecha.dt.hour\n",
        "\n",
        "# One hot encoding de las variables mes, hora y dia\n",
        "df=pd.get_dummies(df, columns=['Hora', 'Dia', 'Mes'])"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Yt8fUxIEiGR"
      },
      "source": [
        "df_train = df[df.index.year < 2021]\n",
        "df_val = df[df.index.year == 2021]\n",
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GsGlIN1FvqZ"
      },
      "source": [
        "Ahora si estamos en condiciones de aplicar el entrenamiento con las variables exógenas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rbd3Imp9ErlW"
      },
      "source": [
        "forecaster = ForecasterAutoreg(\n",
        "    regressor= Ridge(alpha=0.001, normalize=True),\n",
        "    lags= [1, 2, 3, 23, 24, 25, 47, 48, 49]\n",
        ")\n",
        "\n",
        "exog = [column for column in df.columns \n",
        "        if column.startswith(('Dia', 'Hora', 'Mes', 'Festivos'))]\n",
        "\n",
        "forecaster.fit(y=df_train.Demanda, exog=df_train[exog].values)\n"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bbh0W028F3ZW"
      },
      "source": [
        "Y ahora podemos probar la bondad del modelo entrenado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBMc1zJdF8kt"
      },
      "source": [
        "predicciones = backtest_predict_next_24h(\n",
        "    forecaster= forecaster,\n",
        "    y= df_val.Demanda,\n",
        "    exog= df_val[exog],\n",
        "    hour_init_prediction= 11,\n",
        "    verbose= False\n",
        ")\n",
        "\n",
        "error = mean_absolute_error(\n",
        "  y_true = df_val.loc[predicciones.index, 'Demanda'],\n",
        "  y_pred = predicciones\n",
        ")\n",
        "print(f\"Error de backtest (MAP): {error}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9UkqHyMGd1F"
      },
      "source": [
        "y como vemos hay una reducción importante del error (MAP)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWPIvisdGshv"
      },
      "source": [
        "semana = 15\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 7))\n",
        "\n",
        "df_val.loc[ \n",
        "    df_val.index.isocalendar().week == semana, 'Demanda'\n",
        "].plot(ax=ax, linewidth=2, label='validación')\n",
        "\n",
        "predicciones[\n",
        "    predicciones.index.isocalendar().week == semana\n",
        "].plot(ax=ax, linewidth=2, label='predicción')\n",
        "\n",
        "ax.set_title('Predicción vs demanda real')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2VAsodFG5CJ"
      },
      "source": [
        "### Incluir temperatura como predictor\n",
        "\n",
        "Dado que en el set de datos también se dispone de la temperatura, y esta está relacionada con la demanda, podría ser tentador incorporarla como predictor. Sin embargo, esta aproximación no sería correcta ya que, la temperatura no se conoce a futuro. Sí es posible utilizar la previsión de tempratura como un predictor del modelo pero, en tal caso, durante el entrenamiento habría que utilizar la previsión que había en ese momento, no la temperatura real. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tzEgRN6HEVb"
      },
      "source": [
        "## Modelo direct multi-step\n",
        "\n",
        "Los modelos `ForecasterAutoreg` siguen una estrategia de predicción recursiva en la que, cada nueva predicción, se basa en la predicción anterior. Una alternativa es entrenar un modelo para cada uno de los steps que se desea predecir, lo que se conoce como *direct multi-step forecasting*. Si bien es computacionalmente más costosa que la recursiva, puesto que requiere entrenar múltiples modelos, en algunos escenarios, consigue mejores resultados. Este tipo de modelos pueden obtenerse con la clase *ForecasterAutoregMultiOutput* y pueden incluir también una o múltiples variables exógenas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcgqJUIZHlet"
      },
      "source": [
        "### Entrenamiento y tuning del Forecaster\n",
        "\n",
        "A diferencia de cuando se utiliza `ForecasterAutoreg`, en los modelos de tipo `ForecasterAutoregMultiOutput` hay que indicar, en el momento de su creación, el número de steps que se quieren predecir. Esto significa que, el número de predicciones obtenidas al ejecutar el método `predict()`, es siempre el mismo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ix9jrdrH5ar"
      },
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "from skforecast.ForecasterAutoregMultiOutput import ForecasterAutoregMultiOutput\n",
        "\n",
        "\n",
        "forecaster = ForecasterAutoregMultiOutput(\n",
        "    regressor= ElasticNet(),\n",
        "    steps= 36,\n",
        "    lags= 24 # Este valor será remplazado en el grid search\n",
        ")\n",
        "\n",
        "# Hiperparámetros del regresor\n",
        "param_grid = {'alpha': [0.01, 0.1, 1]}\n",
        "\n",
        "# Lags utilizados como predictores\n",
        "lags_grid = [[1, 2, 3, 23, 24]]\n",
        "\n",
        "exog = [column for column in df.columns \n",
        "        if column.startswith(('Dia', 'Hora', 'Mes', 'Festivo'))]\n",
        "\n",
        "resultados_grid = grid_search_forecaster(\n",
        "    forecaster= forecaster,\n",
        "    y= df_train.Demanda,\n",
        "    exog= df_train[exog].values,\n",
        "    param_grid= param_grid,\n",
        "    lags_grid= lags_grid,\n",
        "    steps= 36,\n",
        "    metric= 'mean_absolute_error',\n",
        "    method= 'backtesting',\n",
        "    initial_train_size= len(df_train.Demanda[df_train.index.year < 2020]),\n",
        "    return_best= True,\n",
        "    verbose= False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xm35BW2KqvH"
      },
      "source": [
        "Y el error se calcula de la misma forma que con el forcaster anterior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaXhwsADKyEa"
      },
      "source": [
        "predicciones = backtest_predict_next_24h(\n",
        "    forecaster= forecaster,\n",
        "    y= df_val.Demanda,\n",
        "    exog= df_val[exog],\n",
        "    hour_init_prediction= 11,\n",
        "    verbose= False\n",
        ")\n",
        "\n",
        "error = mean_absolute_error(\n",
        "  y_true = df_val.loc[predicciones.index, 'Demanda'],\n",
        "  y_pred = predicciones\n",
        ")\n",
        "print(f\"Error de backtest (MAP): {error}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7d11bYnK4RF"
      },
      "source": [
        "semana = 15\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 7))\n",
        "\n",
        "df_val.loc[ \n",
        "    df_val.index.isocalendar().week == semana, 'Demanda'\n",
        "].plot(ax=ax, linewidth=2, label='validación')\n",
        "\n",
        "predicciones[\n",
        "    predicciones.index.isocalendar().week == semana\n",
        "].plot(ax=ax, linewidth=2, label='predicción')\n",
        "\n",
        "ax.set_title('Predicción vs demanda real')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMLXOcnKLFI1"
      },
      "source": [
        "## Lo que falta\n",
        "\n",
        "Ahora hay que practicar y realizar un ejercicio, reutilizando todas las herramientas que hemos visto al momento. \n",
        "\n",
        "Si deseas practicar con los mismos datos hay muchas cosas que hacer:\n",
        "\n",
        "1. Explorar entre las opciones de *lags* las que, a partir de su conocimiento experto suenen como las más prometedoras.\n",
        "2. Seleccionar otro método de regresión que pueda ser interesante, de acuerdo a la problemática y dinámica que se conoce de los datos. Explorar los parámetros posibles con una búsqueda ávida.\n",
        "3. Con un modelo seleccionado y entrenado, verificar cuales son los días en los cuales la predicción se distancia de la real fuera del intervalo de confianza. Revisar esos días y tratar de encontrar las causas en los datos existentes."
      ]
    }
  ]
}