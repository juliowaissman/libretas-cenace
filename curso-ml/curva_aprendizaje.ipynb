{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "curva_aprendizaje.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeeBwUsatWeN"
      },
      "source": [
        "<center>\n",
        "<p><img src=\"https://www.gob.mx/cms/uploads/image/file/179499/outstanding_quienes-somos.jpg\" width=\"300\">\n",
        "</p>\n",
        "\n",
        "\n",
        "\n",
        "# Curso *Machine Learning con uso de pandas, scikit learn y libretas jupyter*\n",
        "\n",
        "# Curvas de aprendizaje y búsqueda ávida de parámetros\n",
        "\n",
        "\n",
        "<p> Julio Waissman Vilanova </p>\n",
        "<p>\n",
        "<img src=\"https://identidadbuho.unison.mx/wp-content/uploads/2019/06/letragrama-cmyk-72.jpg\" width=\"80\">\n",
        "</p>\n",
        "</center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x98fCEtpthms"
      },
      "source": [
        "## Generando datos de aprendizaje"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEYX2HZ5tUy_"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as pl\n",
        "\n",
        "rng = np.random.RandomState(0)\n",
        "\n",
        "X = 5 * rng.rand(10000, 1)\n",
        "y = np.sin(X).ravel()\n",
        "\n",
        "# Se agrega un ruido a los datos\n",
        "y[::5] += 3 * (0.5 - rng.rand(X.shape[0] // 5))\n",
        "\n",
        "X_plot = np.linspace(0, 5, 100000)[:, None]"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "np9Vmg7GtmL4"
      },
      "source": [
        "## Usando `grid search` para encontrar el mejor modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7WPpgLZtt35"
      },
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "train_size = 100\n",
        "\n",
        "enr = GridSearchCV(\n",
        "  ElasticNet(),\n",
        "  param_grid={\n",
        "    \"alpha\": np.logspace(-2, 2, 5),\n",
        "    \"l1_ratio\": np.logspace(-2, 2, 5)\n",
        "  }\n",
        ")\n",
        "\n",
        "svr = GridSearchCV(\n",
        "  SVR(kernel='rbf', gamma=0.1),\n",
        "  param_grid={\n",
        "    \"C\": [1e0, 1e1, 1e2, 1e3],\n",
        "    \"gamma\": np.logspace(-2, 2, 5)\n",
        "  }\n",
        ")\n",
        "\n",
        "kr = GridSearchCV(\n",
        "  KernelRidge(kernel='rbf', gamma=0.1),\n",
        "  param_grid={\n",
        "    \"alpha\": [1e0, 0.1, 1e-2, 1e-3],\n",
        "    \"gamma\": np.logspace(-2, 2, 5)\n",
        "  }\n",
        ")\n",
        "\n",
        "enr.fit(X[:train_size], y[:train_size])\n",
        "svr.fit(X[:train_size], y[:train_size])\n",
        "kr.fit(X[:train_size], y[:train_size])\n",
        "\n",
        "print(f\"Para Elastic Net, los menjores parámetros son {enr.best_params_}\")\n",
        "print(f\"Para SVR, los menjores parámetros son {svr.best_params_}\")\n",
        "print(f\"Para Kernel Ridge, los menjores parámetros son {kr.best_params_}\")\n",
        "\n",
        "sv_ratio = svr.best_estimator_.support_.shape[0] / train_size\n",
        "print(\"Support vector ratio: %.3f\" % sv_ratio)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkQxNxj9cyyZ"
      },
      "source": [
        "y_enr = enr.predict(X_plot)\n",
        "y_svr = svr.predict(X_plot)\n",
        "y_kr = kr.predict(X_plot)\n",
        "\n",
        "sv_ind = svr.best_estimator_.support_\n",
        "\n",
        "pl.figure(figsize=(15,7))\n",
        "pl.scatter(\n",
        "  X[sv_ind], y[sv_ind], \n",
        "  c='r', s=50, label='SVR support vectors', zorder=2, edgecolors=(0, 0, 0)\n",
        ")\n",
        "pl.scatter(\n",
        "  X[:100], y[:train_size], \n",
        "  c='k', label='data', zorder=1, edgecolors=(0, 0, 0)\n",
        ")\n",
        "pl.plot(\n",
        "  X_plot, y_enr, \n",
        "  c='r', label='Elastic Net Regression'\n",
        ")\n",
        "pl.plot(\n",
        "  X_plot, y_svr, \n",
        "  c='r', label='Support Vector Regression'\n",
        ")\n",
        "pl.plot(\n",
        "  X_plot, y_kr, \n",
        "  c='g', label='Kernel Ridge Regression'\n",
        ")\n",
        "pl.xlabel('data')\n",
        "pl.ylabel('target')\n",
        "pl.title('Elastic Net SVR vs Kernel Ridge')\n",
        "pl.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE9p0wFbtuyH"
      },
      "source": [
        "## Una función para la curva de aprendizaje\n",
        "\n",
        "En esta función calculamos y graficamos 3 indicadores:\n",
        "\n",
        "1. La curva de aprendizaje tal cual\n",
        "2. El tiempo de entrenamiento conforme crece el conjunto de datos\n",
        "3. La relación entre tiempo de entrenamiento "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nGKLXsRt1Gg"
      },
      "source": [
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "def plot_learning_curve(\n",
        "    estimator, X, y, train_sizes=np.linspace(.1, 1.0, 5), \n",
        "    score='neg_mean_absolute_error', cv=None, n_jobs=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Genera una gráfica de la curva de aprendizaje usando el error en lugar \n",
        "    del score (como acustumbra scikit-learn)\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    estimator : Un estimador con mñetodos `fit`y `predict`\n",
        "\n",
        "    X : ndarray con un shape de (n_samples, n_features)\n",
        "\n",
        "    y : ndarray con un shape shape (n_samples) o (n_samples, n_features)\n",
        "\n",
        "    train_sizes : ndarray de shape (n_ticks,), porcentaje de ejemplos en el\n",
        "        aprendizaje en la curva de aprendizaje. Por default 5 valores entre\n",
        "        el 10% y el 100% (incluidos).\n",
        "\n",
        "    score: string con una medida de score de Scikit-learn. Consultar el manual\n",
        "        para conocer los diferentes scores\n",
        "\n",
        "    cv : int, el K-fold cross-validation. Si None, entonces K = 5\n",
        "\n",
        "    n_jobs : int or None, numero de trabajos en paralelo. Si None entonces 1.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(\n",
        "        estimator, X, y, \n",
        "        scoring=score, cv=cv, n_jobs=n_jobs,\n",
        "        train_sizes=train_sizes,\n",
        "        return_times=True\n",
        "    )\n",
        "\n",
        "    if score.startswith('neg'):\n",
        "        train_error_mean = -np.mean(train_scores, axis=1)\n",
        "        test_error_mean = -np.mean(test_scores, axis=1)\n",
        "    else:\n",
        "        train_error_mean = 1 - np.mean(train_scores, axis=1)\n",
        "        test_error_mean = 1 - np.mean(test_scores, axis=1)   \n",
        "    train_error_std = np.std(train_scores, axis=1)\n",
        "    test_error_std = np.std(test_scores, axis=1)\n",
        "    fit_times_mean = np.mean(fit_times, axis=1)\n",
        "    fit_times_std = np.std(fit_times, axis=1)\n",
        "\n",
        "    # Ahora la graficada\n",
        "    pl.figure(figsize=(18, 7))\n",
        "\n",
        "    # Empezamos con el gráfico de la curva de aprendizaje\n",
        "    pl.subplot(1, 2, 1)\n",
        "    pl.plot(\n",
        "      train_sizes, train_error_mean, 'o-', color=\"r\", label=\"Error entrenamiento\"\n",
        "    )\n",
        "    pl.plot(\n",
        "      train_sizes, test_error_mean, 'o-', color=\"g\", label=\"Error validación\"\n",
        "    )\n",
        "    pl.fill_between(\n",
        "      train_sizes, \n",
        "      train_error_mean - train_error_std,\n",
        "      train_error_mean + train_error_std, \n",
        "      alpha=0.1, color=\"r\"\n",
        "    )\n",
        "    pl.fill_between(\n",
        "      train_sizes, \n",
        "      test_error_mean - test_error_std,\n",
        "      test_error_mean + test_error_std, \n",
        "      alpha=0.1, color=\"g\"\n",
        "    )\n",
        "    pl.title(\"Curva de aprendizaje\")\n",
        "    pl.xlabel(\"Ejemplos de entrenamiento\")\n",
        "    pl.ylabel(\"Error estimado\")\n",
        "    pl.grid()\n",
        "    pl.legend(loc=\"best\")\n",
        "\n",
        "    # Ahora el número de muestras y el tiempo que le tomó procesarlas\n",
        "    pl.subplot(1, 2, 2)\n",
        "    pl.plot(train_sizes, fit_times_mean, 'o-')\n",
        "    pl.fill_between(\n",
        "      train_sizes, \n",
        "      fit_times_mean - fit_times_std,\n",
        "      fit_times_mean + fit_times_std, \n",
        "      alpha=0.1\n",
        "    )\n",
        "    pl.xlabel(\"Ejemplos de entrenamiento\")\n",
        "    pl.ylabel(\"Ajuste en tiempo de computo\")\n",
        "    pl.title(\"Escalabilidad del modelo respecto a tiempos de ejecución\")\n",
        "    pl.grid()\n",
        "\n",
        "    return train_sizes, train_scores, test_scores, fit_times\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93_wfrgRt1iE"
      },
      "source": [
        "## Visualizando la curva de aprendizaje\n",
        "\n",
        "**Para la Regresión rígida**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7HwR8uHt5-z"
      },
      "source": [
        "plot_learning_curve(enr, X, y)\n",
        "pl.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVIpIsVOkYuZ"
      },
      "source": [
        "**Para la regresión por máquinas de vectores de soporte**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvEmuQ3uhjRZ"
      },
      "source": [
        "plot_learning_curve(svr, X, y, cv=3, n_jobs=6)\n",
        "pl.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gySLQgjkfBL"
      },
      "source": [
        "**Para la regresión rígida con Kernel**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ftgv0xsfkU6U"
      },
      "source": [
        "plot_learning_curve(kr, X, y)\n",
        "pl.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}